define({ entries : {
    "Arsenault2025": {
        "abstract": "Artificial intelligence (AI) models have reached a very significant level of accuracy. While their superior performance offers considerable benefits, their inherent complexity often decreases human trust, which slows their application in high-risk decision-making domains, such as finance. The field of explainable AI (XAI) seeks to bridge this gap, aiming to make AI models more understandable. This survey, focusing on published work from 2018 to 2024, categorizes XAI approaches that predict financial time series. In this article, explainability and interpretability are distinguished, emphasizing the need to treat these concepts separately, as they are not applied the same way in practice. Through clear definitions, a rigorous taxonomy of XAI approaches, a complementary characterization, and examples of XAI\u2019s application in the finance industry, this article provides a comprehensive view of XAI\u2019s current role in finance. It can also serve as a guide for selecting the most appropriate XAI approach for future applications.",
        "address": "New York, NY, USA",
        "articleno": "265",
        "author": "Arsenault, Pierre-Daniel and Wang, Shengrui and Patenaude, Jean-Marc",
        "doi": "10.1145/3729531",
        "issn": "0360-0300",
        "issue_date": "October 2025",
        "journal": "ACM Comput. Surv.",
        "keywords": "type: Application, Explainable artificial intelligence, XAI, interpretable model, explainable model, time series, finance",
        "month": "may,",
        "number": "10",
        "numpages": "37",
        "publisher": "Association for Computing Machinery",
        "title": "A Survey of Explainable Artificial Intelligence (XAI) in Financial Time Series Forecasting",
        "type": "article",
        "url": "https://doi.org/10.1145/3729531",
        "volume": "57",
        "year": "2025"
    },
    "Assaf2019": {
        "abstract": "We demonstrate that CNN deep neural networks can not only be used for making predictions based on multivariate time series data, but also for explaining these predictions. This is important for a number of applications where predictions are the basis for decisions and actions. Hence, confidence in the prediction result is crucial. We design a two stage convolutional neural network architecture which uses particular kernel sizes. This allows us to utilise gradient based techniques for generating saliency maps for both the time dimension and the features. These are then used for explaining which features during which time interval are responsible for a given prediction, as well as explaining during which time intervals was the joint contribution of all features most important for that prediction. We demonstrate our approach for predicting the average energy production of photovoltaic power plants and for explaining these predictions.",
        "author": "Assaf, Roy and Schumann, Anika",
        "booktitle": "Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, {IJCAI-19}",
        "doi": "10.24963/ijcai.2019/932",
        "keywords": " type: Application, AI: Machine Learning, AI: Knowledge Representation and Reasoning, Applications: Energy",
        "month": "7",
        "pages": "6488--6490",
        "publisher": "International Joint Conferences on Artificial Intelligence Organization",
        "title": "Explainable Deep Neural Networks for Multivariate Time Series Predictions",
        "type": "inproceedings",
        "url": "https://doi.org/10.24963/ijcai.2019/932",
        "year": "2019"
    },
    "Bochenek2022": {
        "abstract": "In this paper, we performed an analysis of the 500 most relevant scientific articles published since 2018, concerning machine learning methods in the field of climate and numerical weather prediction using the Google Scholar search engine. The most common topics of interest in the abstracts were identified, and some of them examined in detail: in numerical weather prediction research\u2014photovoltaic and wind energy, atmospheric physics and processes; in climate research\u2014parametrizations, extreme events, and climate change. With the created database, it was also possible to extract the most commonly examined meteorological fields (wind, precipitation, temperature, pressure, and radiation), methods (Deep Learning, Random Forest, Artificial Neural Networks, Support Vector Machine, and XGBoost), and countries (China, USA, Australia, India, and Germany) in these topics. Performing critical reviews of the literature, authors are trying to predict the future research direction of these fields, with the main conclusion being that machine learning methods will be a key feature in future weather forecasting.",
        "address": "Basel",
        "author": "Bochenek, Bogdan and Ustrnul, Zbigniew",
        "copyright": "2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.",
        "doi": "10.3390/atmos13020180",
        "issn": "2073-4433",
        "journal": "Atmosphere",
        "keywords": "type: Application, Abstracts ; Algorithms ; Alternative energy ; Artificial intelligence ; Artificial neural networks ; Atmospheric physics ; climate ; Climate change ; Climate prediction ; Climatic analysis ; Climatic extremes ; Datasets ; Decision trees ; Deep learning ; Fields ; Learning algorithms ; Literature reviews ; Machine learning ; Methods ; Neural networks ; Numerical prediction ; Numerical weather forecasting ; numerical weather prediction ; Photovoltaics ; Physics ; Power plants ; Radiation ; Remote sensing ; Renewable resources ; Scientific papers ; Search engines ; Support vector machines ; weather ; Weather forecasting ; Wind power",
        "language": "eng",
        "number": "2",
        "pages": "180-",
        "publisher": "MDPI AG",
        "title": "Machine Learning in Weather Prediction and Climate Analyses\u2014Applications and Perspectives",
        "type": "article",
        "url": "https://doi.org/10.3390/atmos13020180",
        "volume": "13",
        "year": "2022"
    },
    "Dikshit2021": {
        "abstract": "Droughts are one of the disastrous natural hazards which has severe impacts on agricultural production, economy, and society. One of the critical steps for effective drought management is developing a robust forecasting model and understanding how the variables affect the model outcomes. The present study forecasts SPI-12 at a lead time of 3 months, using the Long Short-Term Memory (LSTM) model, and further interprets the spatial and temporal relationship between variables and forecasting results using SHapley Additive exPlanations (SHAP). The developed model is tested in four different regions in New South Wales (NSW), Australia. SPI-12 was computed using monthly rainfall data collected from Scientific Information for Land Owners (SILO) for 1901\u20132018. The model was trained from 1901\u20132000 and tested from 2001\u20132018, and the performance was measured using Coefficient of Determination (R2), Nash\u2013Sutcliffe Efficiency (NSE) and Root-Mean-Square-Error (RMSE). To understand the underlying impact of variables on the model outcomes, SHAPley values were calculated for the entire testing period and also at three different temporal ranges, which are during the Millennium Drought (2001\u20132010), post drought period (2011\u20132018) and at a seasonal scale (summer months). The comparison of the results shows a significant variation in the impact of variables on forecasting, both temporally and spatially. It also shows the need to study the model outcomes for specific regions and for a shorter duration than the entire testing period. This is a first of its study towards interpreting the forecasting model in drought studies, which could help understand the behaviour of drought variables. [Display omitted] \u2022Forecasting SPI drought index using LSTM for New South Wales.\u2022Understanding the influence of climate drivers towards drought occurrence.\u2022Shapley additive explanation is used to interpret the forecasting results.",
        "author": "Dikshit, Abhirup and Pradhan, Biswajeet",
        "copyright": "2021 The Authors",
        "doi": "10.1016/j.mlwa.2021.100192",
        "issn": "2666-8270",
        "journal": "Machine learning with applications",
        "keywords": "Deep learning ; Drought forecasting ; Explainable AI ; Standard precipitation index",
        "language": "eng",
        "pages": "100192-",
        "publisher": "Elsevier Ltd",
        "title": "Explainable AI in drought forecasting",
        "type": "article Application",
        "url": "https://doi.org/10.1016/j.mlwa.2021.100192",
        "volume": "6",
        "year": "2021"
    },
    "Dwivedi2023": {
        "abstract": "As our dependence on intelligent machines continues to grow, so does the demand for more transparent and interpretable models. In addition, the ability to explain the model generally is now the gold standard for building trust and deployment of artificial intelligence systems in critical domains. Explainable artificial intelligence (XAI) aims to provide a suite of machine learning techniques that enable human users to understand, appropriately trust, and produce more explainable models. Selecting an appropriate approach for building an XAI-enabled application requires a clear understanding of the core ideas within XAI and the associated programming frameworks. We survey state-of-the-art programming techniques for XAI and present the different phases of XAI in a typical machine learning development process. We classify the various XAI approaches and, using this taxonomy, discuss the key differences among the existing XAI techniques. Furthermore, concrete examples are used to describe these techniques that are mapped to programming frameworks and software toolkits. It is the intention that this survey will help stakeholders in selecting the appropriate approaches, programming frameworks, and software toolkits by comparing them through the lens of the presented taxonomy.",
        "address": "New York, NY, USA",
        "articleno": "194",
        "author": "Dwivedi, Rudresh and Dave, Devam and Naik, Het and Singhal, Smiti and Omer, Rana and Patel, Pankesh and Qian, Bin and Wen, Zhenyu and Shah, Tejal and Morgan, Graham and Ranjan, Rajiv",
        "doi": "10.1145/3561048",
        "issn": "0360-0300",
        "issue_date": "September 2023",
        "journal": "ACM Comput. Surv.",
        "keywords": "type: Technique, Explainable artificial intelligence, interpretable AI, programming framework, software toolkits",
        "month": "jan,",
        "number": "9",
        "numpages": "33",
        "publisher": "Association for Computing Machinery",
        "title": "Explainable AI (XAI): Core Ideas, Techniques, and Solutions",
        "type": "article",
        "url": "https://doi.org/10.1145/3561048",
        "volume": "55",
        "year": "2023"
    },
    "Garreau2020": {
        "abstract": "Machine learning is used more and more often for sensitive applications, sometimes replacing humans in critical decision-making processes. As such, interpretability of these algorithms is a pressing need. One popular algorithm to provide interpretability is LIME (Local Interpretable Model-Agnostic Explanation). In this paper, we provide the first theoretical analysis of LIME. We derive closed-form expressions for the coefficients of the interpretable model when the function to explain is linear. The good news is that these coefficients are proportional to the gradient of the function to explain: LIME indeed discovers meaningful features. However, our analysis also reveals that poor choices of parameters can lead LIME to miss important features.",
        "author": "Garreau, Damien and von Luxburg, Ulrike",
        "booktitle": "Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics",
        "editor": "Chiappa, Silvia and Calandra, Roberto",
        "month": "26--28 Aug",
        "pages": "1287--1296",
        "pdf": "http://proceedings.mlr.press/v108/garreau20a/garreau20a.pdf",
        "publisher": "PMLR",
        "series": "Proceedings of Machine Learning Research",
        "title": "Explaining the Explainer: A First Theoretical Analysis of LIME",
        "type": "InProceedings",
        "url": "https://proceedings.mlr.press/v108/garreau20a.html",
        "volume": "108",
        "year": "2020"
    },
    "Jim\u00e9nez-Navarro2024": {
        "abstract": "Urban air pollution represents a significant threat to public health and the environment, with nitrogen oxides, ozone, and particulate matter being among the most harmful pollutants. These contribute to respiratory and cardiovascular diseases, particularly in urban areas with high traffic and elevated temperatures. Machine learning, especially deep learning, shows promise in enhancing the prediction accuracy of prediction of pollutant's concentrations. However, the \u201cblack box\u201d nature of these models often limits their interpretability, which is crucial for informed decision-making. Our study introduces a Temporal Selection Layer technique within deep learning models for time series forecasting to tackle this issue. This technique not only improves prediction accuracy by embedding feature selection directly into the neural network, but also enhances interpretability and reduces computational costs. In particular, we applied this method to hourly concentration data of pollutants, including particulate matter, ozone, and nitrogen oxides, from five urban monitoring sites in Graz, Austria. These concentrations were used as target variables to predict, while identifying the most relevant features and periods that affect prediction accuracy. Comparative analysis with other embedded feature selection methods showed that the Temporal Selection Layer significantly enhances both model effectiveness and transparency. Additionally, we applied explainable techniques to evaluate the impact of weather and time-related factors on air pollution, which also helped assess feature importance. The results show that our approach improves both prediction accuracy and model interpretability, leading finally to more effective pollution management strategies. \u2022Major pollutants contribute to respiratory and cardiovascular diseases, especially in high-traffic and hot urban areas.\u2022\u201cTemporal Selection Layer\u201d enhance deep learning by integrating feature selection, improving accuracy, interpretability, and efficiency.\u2022This study employs a multivariate hourly pollutant data from five urban sites in Graz, Austria.\u2022Explainable techniques were used to evaluate how past factors influence future pollution levels.",
        "author": "Jim\u00e9nez-Navarro, Manuel J. and Lovri\u0107, Mario and Kecorius, Simonas and Nyarko, Emmanuel Karlo and Mart\u00ednez-Ballesteros, Mar\u00eda",
        "copyright": "2024 The Authors",
        "doi": "10.1016/j.rineng.2024.103290",
        "issn": "2590-1230",
        "journal": "Results in engineering",
        "keywords": "Air pollution ; Deep learning ; Feature selection ; Time series forecasting ; XAI",
        "language": "eng",
        "pages": "103290-",
        "publisher": "Elsevier B.V",
        "title": "Explainable deep learning on multi-target time series forecasting: An air pollution use case",
        "type": "article Application",
        "url": "https://doi.org/10.1016/j.rineng.2024.103290",
        "volume": "24",
        "year": "2024"
    },
    "Menghani2023": {
        "abstract": "Deep learning has revolutionized the fields of computer vision, natural language understanding, speech recognition, information retrieval, and more. However, with the progressive improvements in deep learning models, their number of parameters, latency, and resources required to train, among others, have all increased significantly. Consequently, it has become important to pay attention to these footprint metrics of a model as well, not just its quality. We present and motivate the problem of efficiency in deep learning, followed by a thorough survey of the five core areas of model efficiency (spanning modeling techniques, infrastructure, and hardware) and the seminal work there. We also present an experiment-based guide along with code for practitioners to optimize their model training and deployment. We believe this is the first comprehensive survey in the efficient deep learning space that covers the landscape of model efficiency from modeling techniques to hardware support. It is our hope that this survey would provide readers with the mental model and the necessary understanding of the field to apply generic efficiency techniques to immediately get significant improvements, and also equip them with ideas for further research and experimentation to achieve additional gains.",
        "address": "New York, NY, USA",
        "articleno": "259",
        "author": "Menghani, Gaurav",
        "doi": "10.1145/3578938",
        "issn": "0360-0300",
        "issue_date": "December 2023",
        "journal": "ACM Comput. Surv.",
        "keywords": "type: Technique, Efficient deep learning, efficient machine learning, efficient artificial intelligence, quantization, pruning, sparsity, distillation, model compression, model optimization",
        "month": "mar,",
        "number": "12",
        "numpages": "37",
        "publisher": "Association for Computing Machinery",
        "title": "Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better",
        "type": "article",
        "url": "https://doi.org/10.1145/3578938",
        "volume": "55",
        "year": "2023"
    },
    "Mosca2022": {
        "abstract": "\"Model explanations are crucial for the transparent, safe, and trustworthy deployment of machine learning models. The \\textit{SHapley Additive exPlanations} (SHAP) framework is considered by many to be a gold standard for local explanations thanks to its solid theoretical background and general applicability. In the years following its publication, several variants appeared in the literature{---}presenting adaptations in the core assumptions and target applications. In this work, we review all relevant SHAP-based interpretability approaches available to date and provide instructive examples as well as recommendations regarding their applicability to NLP use cases.\"",
        "address": "\"Gyeongju, Republic of Korea\",",
        "author": "\"Mosca, Edoardo  and Szigeti, Ferenc  and Tragianni, Stella  and Gallagher, Daniel  and Groh, Georg\",",
        "booktitle": "\"Proceedings of the 29th International Conference on Computational Linguistics\",",
        "doi": "\"https://aclanthology.org/2022.coling-1.406/\",",
        "editor": "\"Calzolari, Nicoletta  and Huang, Chu-Ren  and Kim, Hansaem  and Pustejovsky, James  and Wanner, Leo  and Choi, Key-Sun  and Ryu, Pum-Mo  and Chen, Hsin-Hsi  and Donatelli, Lucia  and Ji, Heng  and Kurohashi, Sadao  and Paggio, Patrizia  and Xue, Nianwen  and Kim, Seokhwan  and Hahm, Younggyun  and He, Zhong  and Lee, Tony Kyungil  and Santus, Enrico  and Bond, Francis  and Na, Seung-Hoon\",",
        "month": "oct,",
        "pages": "\"4593--4603\",",
        "publisher": "\"International Committee on Computational Linguistics\",",
        "title": "\"{SHAP}-Based Explanation Methods: A Review for {NLP} Interpretability\",",
        "type": "inproceedings",
        "url": "\"https://aclanthology.org/2022.coling-1.406/\",",
        "year": "\"2022\","
    },
    "Yu2019": {
        "abstract": "Recurrent neural networks (RNNs) have been widely adopted in research areas concerned with sequential data, such as text, audio, and video. However, RNNs consisting of sigma cells or tanh cells are unable to learn the relevant information of input data when the input gap is large. By introducing gate functions into the cell structure, the long short-term memory (LSTM) could handle the problem of long-term dependencies well. Since its introduction, almost all the exciting results based on RNNs have been achieved by the LSTM. The LSTM has become the focus of deep learning. We review the LSTM cell and its variants to explore the learning capacity of the LSTM cell. Furthermore, the LSTM networks are divided into two broad categories: LSTM-dominated networks and integrated LSTM networks. In addition, their various applications are discussed. Finally, future research directions are presented for LSTM networks.",
        "author": "Yu, Yong and Si, Xiaosheng and Hu, Changhua and Zhang, Jianxun",
        "doi": "10.1162/neco_a_01199",
        "eprint": "https://direct.mit.edu/neco/article-pdf/31/7/1235/1053200/neco\\_a\\_01199.pdf",
        "issn": "0899-7667",
        "journal": "Neural Computation",
        "keywords": "type: Technique, Explainable artificial intelligence, interpretable AI, programming framework, software toolkits",
        "month": "07",
        "number": "7",
        "pages": "1235-1270",
        "title": "A Review of Recurrent Neural Networks: LSTM Cells and Network Architectures",
        "type": "article",
        "url": "https://doi.org/10.1162/neco\\_a\\_01199",
        "volume": "31",
        "year": "2019"
    }
}});